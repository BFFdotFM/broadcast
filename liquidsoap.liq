# WARNING! This file is automatically generated by AzuraCast.
# Do not update it directly!


# Custom Configuration (Specified in Station Profile)
### BEGIN: BFF.fm Configuration and Secrets ###
### Secrets should not be checked in. Duh.

# Creek CMS integration
creek_app_id = ref("fm.bff.example")
creek_api_base = ref("https://")
creek_public_base = ref("https://")

# Harbor Ingest configuration
icecast_port = ref(8005)

# Ingest precedence stacks all created HTTP harbors (by name) to create the cascade by which on-air is determined.
# The names need to match the names of ingest sources created later.
# TODO: DRY: Find a clean way to build this list implicitly
ingest_channel_precedence = ref([
  "Emergency Broadcast",
  "Remote DJ",
  "Studio F",
  "Studio A",
  "Studio Automation"
])

ingest_studio_a_password = ref("(PASSWORD)")
ingest_studio_f_password = ref("(PASSWORD)")
ingest_automation_password = ref("(PASSWORD)")
ingest_emergency_password = ref("(PASSWORD)")

# Configure Last.FM scrobbling
lastfm_app_id = ref("(PASSWORD)")
lastfm_app_secret = ref("(PASSWORD)")
lastfm_session_token = ref("(PASSWORD)") # @bffdotfm

# Prefix all Slack logs with this text:
slack_message_prefix = ref(":safety_vest: ")
slack_default_channel = ref("(PASSWORD)")
slack_named_channels = ref([
  ("alerts", slack_default_channel),
  ("stream_auth", slack_default_channel),
  ("now_playing", ref("(PASSWORD)"))
])

tunein_partner_id = ref("(PASSWORD)")
tunein_partner_key =  ref("(PASSWORD)")
tunein_station_id = ref("(PASSWORD)")

user_agent_name = ref("BFF.fm Broadcast System")
user_agent_url = ref("https://bff.fm")

### END: BFF.fm Configuration and Secrets ###

init.daemon.set(false)
init.daemon.pidfile.path.set("/var/azuracast/stations/bff.fm_azupgrade_station/config/liquidsoap.pid")

log.stdout.set(true)
log.file.set(false)

settings.server.log.level.set(4)

settings.server.socket.set(true)
settings.server.socket.permissions.set(0o660)
settings.server.socket.path.set("/var/azuracast/stations/bff.fm_azupgrade_station/config/liquidsoap.sock")

settings.harbor.bind_addrs.set(["0.0.0.0"])

settings.tag.encodings.set(["UTF-8","ISO-8859-1"])
settings.encoder.metadata.export.set(["artist","title","album","song"])

setenv("TZ", "UTC")

autodj_is_loading = ref(true)
ignore(autodj_is_loading)

autodj_ping_attempts = ref(0)
ignore(autodj_ping_attempts)

# Track live-enabled status.
live_enabled = ref(false)
ignore(live_enabled)

# Track live transition for crossfades.
to_live = ref(false)
ignore(to_live)

azuracast_api_url = "http://127.0.0.1:6010/api/internal/1/liquidsoap"
azuracast_api_key = "(PASSWORD)"

def azuracast_api_call(~timeout_ms=2000, url, payload) =
    full_url = "#{azuracast_api_url}/#{url}"

    log("API #{url} - Sending POST request to '#{full_url}' with body: #{payload}")
    try
        response = http.post(full_url,
            headers=[
                ("Content-Type", "application/json"),
                ("User-Agent", "Liquidsoap AzuraCast"),
                ("X-Liquidsoap-Api-Key", "#{azuracast_api_key}")
            ],
            timeout_ms=timeout_ms,
            data=payload
        )

        log("API #{url} - Response (#{response.status_code}): #{response}")
        "#{response}"
    catch err do
        log("API #{url} - Error: #{error.kind(err)} - #{error.message(err)}")
        "false"
    end
end

station_media_dir = "/var/azuracast/stations/bff.fm_azupgrade_station/media"
def azuracast_media_protocol(~rlog=_,~maxtime=_,arg) =
    ["#{station_media_dir}/#{arg}"]
end

add_protocol(
    "media",
    azuracast_media_protocol,
    doc="Pull files from AzuraCast media directory.",
    syntax="media:uri"
)

# Custom Configuration (Specified in Station Profile)
### BEGIN: BFF.fm Library Code ###

## Time Utilities
# Shorthands for various time formats from the system time

let timestamp = ()

def timestamp.custom(format="%T") =
  list.hd(default="", process.read.lines(env=[("TZ", ":America/Los_Angeles"), ("FORMAT", format)], "date +$FORMAT"))
end

def timestamp.hms() =
  timestamp.custom("%T")
end

def timestamp.iso8609() =
  timestamp.custom("%Y-%m-%dT%H:%M:%S")
end

def timestamp.ymdhms() =
  timestamp.custom("%Y%m%dT%H%M%S")
end

def timestamp.unix() =
  timestamp.custom("%s")
end

## Hash and Crypto

let hash = ()

def hash.md5(str) =
  md5sum = file.which("md5sum")
  log.debug("Path to md5sum: #{md5sum}")
  # md5sum returns the form "<HASH> -", so split away just the hash w/ awk:
  list.hd(default="", process.read.lines(env=[("STR", str)], "printf %s \"$STR\" | #{md5sum} | awk '{ print $1 }'"))
end

## Curl HTTP functions
# We need to POST and GET data via CURL, these wrappers provide some sugar around the build-in http.get/post

let curl = ()
let curl.version = ref(list.hd(default="curl/unknown", process.read.lines("curl --version | head -1 | awk '{ print $1 \"/\" $2 }'")))
let curl.userAgent = ref("LiquidSoap/#{liquidsoap.version} (#{!curl.version}) #{!user_agent_name} <#{!user_agent_url}>")


def curl.json(~data=[], ~timeout_ms=2000, theUrl) =
  http.post(theUrl,
    headers=[
      ("User-Agent", !curl.userAgent),
      ("Content-Type", "application/json")
    ],
    timeout_ms=timeout_ms,
    data=json.stringify(data)
  )
end

def curl.post(~data=[], ~timeout_ms=2000, theUrl) =
  def buildDataString(data, arg) =
    data ^ fst(arg) ^ "=" ^ url.encode(snd(arg)) ^ "&"
  end
  formData = list.fold(buildDataString, "", data)

  http.post(theUrl,
    headers=[
      ("User-Agent", !curl.userAgent),
      ("Content-Type", "application/x-www-form-urlencoded")
    ],
    timeout_ms=timeout_ms,
    data=formData
  )
end

def curl.fetch(~timeout_ms=2000, theUrl) =
  http.get(theUrl, headers=[("User-Agent", !curl.userAgent)], timeout_ms=timeout_ms)
end

## BFF.fm API functions
#
# BFF.fm CMS is a forked version of Creek, along with some of our own deployment idiocyncracies,
# so this wrapper makes calling the API easier
let bff = ()
let bff.appId = creek_app_id
let bff.base = creek_api_base
let bff.publicBase = creek_public_base

def bff.fetch(~cacheBust=false, endpoint)
  appendUrl = if (cacheBust == true) then
    "&cacheBust=#{timestamp.unix()}"
  else
    ""
  end

  fullApiCallUrl = "#{!bff.base}/api/#{endpoint}?app_id=#{url.encode(!bff.appId)}#{appendUrl}"
  response = curl.fetch(fullApiCallUrl)

  if (response.status_code == 200) then
    "#{response}"
  else
    ""
  end
end

def bff.post(~data=[], endpoint)
  url = "#{!bff.base}/api/#{endpoint}"
  fullData = list.append([
    ('app_id', !bff.appId)
  ], data)
  response = curl.post(data=fullData, url)

  if (response.status_code == 200) then
    "#{response}"
  else
    ""
  end
end

# Create a special "now" endpoint shortlink that will direct users to the most relevant show/broadcast
# destination based on the time of the URL:
#
# e.g. https://bff.fm/now/20200209T115500
def bff.nowUrl() =
  "#{creek_public_base}/now/#{timestamp.ymdhms()}"
end

## Slack Functions
# BFF.fm makes heavy use of Slack for all our community organizing and a lot of technical monitoring.

let slack = ()

# Configure as pairs of named channels, plus the unique `ABCD/1234` part of the WebHook URL configured
# through an app at https://api.slack.com/apps
#
# You must specify a default.
let slack.defaultChannel = slack_default_channel
let slack.channels = slack_named_channels
let slack.messagePrefix = slack_message_prefix

def slack.send(hook, message) =
  payload = [("text", "[#{timestamp.hms()}] #{!slack.messagePrefix}#{message}"), ("type", "mrkdwn")]
  ignore(curl.json(data=payload, "https://hooks.slack.com/services/#{hook}"))
end

def slack.log(~channel = "", message) =
  channelHook = list.assoc(default=slack.defaultChannel, channel, !slack.channels)
  ignore(slack.send(channelHook, message))
end

## Last.FM Functions
#
# Last.FM integration can also be provided via an extension for LiquidSoap, but it's not shipping in AzuraCast at this
# time, so we implemented the `track.scrobble` API ourselves.
#
# You'll need to create an app at https://www.last.fm/api and then auth your account against it to get a Session token
# and store it all in the config above.
let lastfm = ()

let lastfm.apiBase = ref("https://ws.audioscrobbler.com/2.0/")
let lastfm.appId = lastfm_app_id
let lastfm.appSecret = lastfm_app_secret
let lastfm.sessionToken = lastfm_session_token

def lastfm.scrobble(~artist, ~track, ~album="") =

  log.info("Scrobbling: #{track} by #{artist} (Album: #{album})")

  # parameters in alphabetical order
  params = [
    ("album", album),
    ("api_key", !lastfm.appId),
    ("artist", artist),
    ("method", "track.scrobble"),
    ("sk", !lastfm.sessionToken),
    ("timestamp", timestamp.unix()),
    ("track", track),
  ]

  def flattenSignatureParam(output, p) =
    output ^ fst(p) ^ snd(p)
  end

  hashableParamString = list.fold(flattenSignatureParam, "", params) ^ !lastfm.appSecret
  apiSignature = hash.md5(hashableParamString)
  fullParams = list.append(params, [("api_sig", apiSignature)])
  ignore(curl.post(data=fullParams, !lastfm.apiBase))
end

# While we now pull our playing data from a richer JSON API, this function handles the common
# Artist - Track string format that might be passed around your automation system.
def lastfm.scrobbleNowPlayingString(nowPlaying) =
  parts = list.map(string.trim, string.split(separator="-", nowPlaying))

  if (list.length(parts) == 2) then
    artist = list.hd(default="", parts)
    track = list.nth(default="", parts, 1)
    lastfm.scrobble(artist=artist, track=track)
  else
    log.important("Could not attempt scrobbling #{nowPlaying}, did not split into 2 parts")
  end
end

## TuneIn AIR Support
# AzuraCast does have some native support for TuneIN, but since we're pulling richer track
# metadata (see below), we've implemented it directly.

let tunein = ()
let tunein.apiBase = ref("http://air.radiotime.com/Playing.ashx")
let tunein.partnerId = tunein_partner_id
let tunein.partnerKey = tunein_partner_key
let tunein.stationId = tunein_station_id

def tunein.airRequest(params) =
  fullParams = list.append([
    ("partnerId", !tunein.partnerId),
    ("partnerKey", !tunein.partnerKey),
    ("id", !tunein.stationId)
  ], params)
  ignore(curl.post(data=fullParams, !tunein.apiBase))
end

def tunein.nowPlaying(~artist, ~track, ~album="") =
  log.info("Logging to TuneIn AIR NOW: #{track} by #{artist} (Album: #{album})")
  tunein.airRequest([
    ("artist", artist),
    ("title", track),
    ("album", album)
  ])
end

def tunein.nonMusic(~attribution, ~name) =
  log.info("Logging non-music to TuneIn AIR NOW: #{name} attributed to #{attribution}")
  tunein.airRequest([
    ("artist", attribution),
    ("title", name),
#    ("commercial", "true")
  ])
end

## Twitter Support
# Support composing Tweets

let twitter = ()
let twitter.apiBase = ref("https://api.twitter.com")
let twitter.consumeKey = ref("")
let twitter.consumerSecret = ref("")
let twitter.userToken = ref("")
let twitter.userTokenSecret = ref("")

def twitter.tweet(message) =
  log.info("Twitter: Not Impemented Yet")
  "#{message}"
end

### END: BFF.fm Library Code ###

playlist_default = playlist(id="playlist_default",mime_type="audio/x-mpegurl",mode="randomize",reload_mode="watch","/var/azuracast/stations/bff.fm_azupgrade_station/playlists/playlist_default.m3u")
playlist_default = cue_cut(id="cue_playlist_default", playlist_default)

# Standard Playlists
radio = random(id="standard_playlists", weights=[3], [playlist_default])

# AutoDJ Next Song Script
def autodj_next_song() =
    response = azuracast_api_call(
        "nextsong",
        ""
    )
    if (response == "") or (response == "false") then
        null()
    else
        r = request.create(response)
        if request.resolve(r) then
            r
        else
            null()
       end
    end
end

# Delayed ping for AutoDJ Next Song
def wait_for_next_song(autodj)
    autodj_ping_attempts := !autodj_ping_attempts + 1

    if source.is_ready(autodj) then
        log("AutoDJ is ready!")
        autodj_is_loading := false
        -1.0
    elsif !autodj_ping_attempts > 200 then
        log("AutoDJ could not be initialized within the specified timeout.")
        autodj_is_loading := false
        -1.0
    else
        0.5
    end
end

dynamic = request.dynamic(id="next_song", timeout=20., retry_delay=10., autodj_next_song)
dynamic = cue_cut(id="cue_next_song", dynamic)

dynamic_startup = fallback(
    id = "dynamic_startup",
    track_sensitive = false,
    [
        dynamic,
        source.available(
            blank(id = "autodj_startup_blank", duration = 120.),
            predicate.activates({!autodj_is_loading})
        )
    ]
)
radio = fallback(id="autodj_fallback", track_sensitive = true, [dynamic_startup, radio])

ref_dynamic = ref(dynamic);
thread.run.recurrent(delay=0.25, { wait_for_next_song(!ref_dynamic) })

requests = request.queue(id="requests")
requests = cue_cut(id="cue_requests", requests)
radio = fallback(id="requests_fallback", track_sensitive = true, [requests, radio])

interrupting_queue = request.queue(id="interrupting_requests")
interrupting_queue = cue_cut(id="cue_interrupting_requests", interrupting_queue)
radio = fallback(id="interrupting_fallback", track_sensitive = false, [interrupting_queue, radio])

def add_skip_command(s) =
    def skip(_) =
        source.skip(s)
        "Done!"
    end

    server.register(namespace="radio", usage="skip", description="Skip the current song.", "skip",skip)
end

add_skip_command(radio)

def live_aware_crossfade(old, new) =
    if !to_live then
        # If going to the live show, play a simple sequence
        sequence([fade.out(old.source),fade.in(new.source)])
    else
        # Otherwise, use the smart transition
        cross.simple(old.source, new.source, fade_in=2.00, fade_out=2.00)
    end
end

radio = cross(minimum=0., duration=3.00, live_aware_crossfade, radio)

# Custom Configuration (Specified in Station Profile)
### BEGIN: BFF.fm drop default metadata  ###

# Custom Configuration (Specified in Station Profile)
# Drop the default Azuracast fallback metadata
radio = drop_metadata(radio)

### END: BFF.fm drop default metadata  ###

# DJ Authentication
last_authenticated_dj = ref("")
live_dj = ref("")

def dj_auth(login) =
    auth_info =
        if (login.user == "source" or login.user == "") and (string.match(pattern="(:|,)+", login.password)) then
            auth_string = string.split(separator="(:|,)", login.password)
            {user = list.nth(default="", auth_string, 0),
            password = list.nth(default="", auth_string, 2)}
        else
            {user = login.user, password = login.password}
        end

    response = azuracast_api_call(
        timeout_ms=5000,
        "auth",
        json.stringify(auth_info)
    )

    if (response == "true") then
        last_authenticated_dj := auth_info.user
        true
    else
        false
    end
end

def live_connected(header) =
    dj = !last_authenticated_dj
    log("DJ Source connected! Last authenticated DJ: #{dj} - #{header}")

    live_enabled := true
    live_dj := dj

    _ = azuracast_api_call(
        timeout_ms=5000,
        "djon",
        json.stringify({user = dj})
    )
end

def live_disconnected() =
    _ = azuracast_api_call(
        timeout_ms=5000,
        "djoff",
        json.stringify({user = !live_dj})
    )

    live_enabled := false
    live_dj := ""
end

# A Pre-DJ source of radio that can be broadcast if needed',
radio_without_live = radio
ignore(radio_without_live)

# Live Broadcasting
live = input.harbor("/", id = "input_streamer", port = 8005, auth = dj_auth, icy = true, icy_metadata_charset = "UTF-8", metadata_charset = "UTF-8", on_connect = live_connected, on_disconnect = live_disconnected, buffer = 5.00, max = 10.00)

def insert_missing(m) =
    if m == [] then
        [("title", "Live Broadcast"), ("is_live", "true")]
    else
        [("is_live", "true")]
    end
end
live = map_metadata(insert_missing, live)

radio = fallback(id="live_fallback", replay_metadata=true, [live, radio])

# Skip non-live track when live DJ goes live.
def check_live() =
    if live.is_ready() then
        if not !to_live then
            to_live := true
            radio_without_live.skip()
        end
    else
        to_live := false
    end
end

# Continuously check on live.
radio = source.on_frame(radio, check_live)

# Allow for Telnet-driven insertion of custom metadata.
radio = server.insert_metadata(id="custom_metadata", radio)

# Apply amplification metadata (if supplied)
radio = amplify(override="liq_amplify", 1., radio)

# Normalization and Compression
radio = normalize(target = 0., window = 0.03, gain_min = -16., gain_max = 0., radio)
radio = compress.exponential(radio, mu = 1.0)

radio = fallback(id="safe_fallback", track_sensitive = false, [radio, single(id="error_jingle", "/usr/local/share/icecast/web/error.mp3")])

# Send metadata changes back to AzuraCast
last_title = ref("")
last_artist = ref("")

def metadata_updated(m) =
    def f() =
        if (m["title"] != !last_title or m["artist"] != !last_artist) then
            last_title := m["title"]
            last_artist := m["artist"]

            j = json()

            if (m["song_id"] != "") then
                j.add("song_id", m["song_id"])
                j.add("media_id", m["media_id"])
                j.add("playlist_id", m["playlist_id"])
            else
                j.add("artist", m["artist"])
                j.add("title", m["title"])
            end

            _ = azuracast_api_call(
                "feedback",
                json.stringify(j)
            )
        end
    end

    thread.run(f)
end

radio.on_metadata(metadata_updated)

# Handle "Jingle Mode" tracks by replaying the previous metadata.
last_metadata = ref([])
def handle_jingle_mode(m) =
    if (m["jingle_mode"] == "true") then
        !last_metadata
    else
        last_metadata := m
        m
    end
end

radio = metadata.map(update=false, handle_jingle_mode, radio)

# Custom Configuration (Specified in Station Profile)
### BEGIN: BFF.fm Ingest Harbors ###

# Reset the above and remove the default Azuracast autodj mount from the
ignore(radio)

# If running an automation playlist through AzuraCast, assign `radio_without_live` instead
radio = single(id="no_broadcast", "/usr/local/share/icecast/web/error.mp3")

# Manage Icecast input harbors remote DJs and Studios
let ingest = ()
let ingest.icecastPort = icecast_port
# Precedence needs to match the names of ingest sources created below.
# TODO: DRY: Refactor so that this is implicit based on the create of channels below.
let ingest.precedence = ingest_channel_precedence
let ingest.connections = ref([])

# Is a named studio currently connected?
def ingest.isConnected(studio) =
  dj = list.assoc(default="", studio, !ingest.connections)
  (dj != "")
end

# Who is connected to a named studio?
def ingest.djFor(studio) =
  def listToString(str, item) =
    str ^ "#{fst(item)} => #{snd(item)}"
  end
  connectionsDebug = list.fold(listToString, "", !ingest.connections)
  log.debug("Connections: #{connectionsDebug}")

  list.assoc(default="", studio, !ingest.connections)
end

# Who is the current on-air DJ, based on studio precedence?
def ingest.currentDj() =
  # Get the DJ for the highest precedence studio that has a DJ
  def getDj(current, studio) =
    if (current != "") then
      current
    else
      ingest.djFor(studio)
    end
  end
  list.fold(getDj, "", !ingest.precedence)
end

# Global “on connection” handler
def ingest.onDjConnect() =
  dj_name = ingest.currentDj()
  if (dj_name != "") then
    _ = azuracast_api_call(
      timeout_ms=5000,
      "djon",
      json.stringify({user = dj_name})
    )
    #log.debug("AzuraCast remote DJ connected response: #{ret}")
    slack.log(":rotating_light: ON AIR: *#{dj_name}*")
  end
end

# Global “on disconnect handler
def ingest.onDjDisconnect() =
  dj_name = ingest.currentDj()
  log.debug("Source disconnected. Current broadcaster was: #{dj_name}")

  if (dj_name != "") then
    _ = azuracast_api_call(
      timeout_ms=5000,
      "djoff",
      json.stringify({user = dj_name})
    )
  end
end

# Handle parsing of username:password strings from legacy clients
def ingest.parseCredentials(login) =
  if (login.user == "source" or login.user == "") and (string.match(pattern="(:|,)+", login.password)) then
    auth_string = string.split(separator="(:|,)", login.password)
    {user = list.nth(default="", auth_string, 0),
    password = list.nth(default="", auth_string, 2)}
  else
    {user = login.user, password = login.password}
  end
end

# Create a studio source
# — These sources have a single fixed password baked into the configuration.
def ingest.makeStudioSource(studioName, ~mount, ~username="source", ~password, ~dropMetadata=false) =
  def studioAuth(login) =
    auth_info = ingest.parseCredentials(login)

    if ((auth_info.user == username) and (auth_info.password == password )) then
      ingest.connections := list.add((studioName, username), !ingest.connections)
      log.info("Studio connected: #{username}")
      true
    else
      ingest.connections := list.assoc.remove(studioName, !ingest.connections)
      log.important("Studio authentication failed: #{username}")
      false
    end
  end

  # When a studio connects, announce to monitoring destinations
  def connected(header) =
    log.info("#{studioName} source connected! - #{header}")
    slack.log(":zap: #{studioName} source connected (*#{ingest.djFor(studioName)}*)")

    # Trigger global connection handler, which will update on-air metadata if
    # this studio is top of the precedence stack
    ingest.onDjConnect()
  end

  # When a studio disconnects, announce to monitoring destinations
  def disconnected() =
    log("#{studioName} disconnected!")
    slack.log(":end: #{studioName} disconnected (*#{ingest.djFor(studioName)}*)")
    ingest.onDjDisconnect()

    # Clear studio DJ variables
    ingest.connections := list.assoc.remove(studioName, !ingest.connections)

    # Reset metadata for other remaining connected streams
    ingest.onDjConnect()
  end

  # Create an IceCast harbor for this studio
  harbor = audio_to_stereo(input.harbor(mount, port = !ingest.icecastPort, auth = studioAuth, icy = true, icy_metadata_charset = "UTF-8", metadata_charset = "UTF-8", on_connect = connected, on_disconnect = disconnected, buffer = 10., max = 15.))
  ignore(output.dummy(harbor, fallible=true))

  # return the source
  if (dropMetadata == true) then
    drop_metadata(harbor)
  else
    harbor
  end
end

# Create an remote DJ source authenticated against AzuraCast's 'streamers' database
def ingest.makeAzuraCastStreamerSource(studioName, ~mount, ~dropMetadata=false) =
  # Keep track of who the last DJ was so we can monitor when it changes.
  lastDj = ref("")

  def azuracastAuth(login) =
    auth_info = ingest.parseCredentials(login)
    response = azuracast_api_call(
      timeout_ms=5000,
      "auth",
      json.stringify(auth_info)
    )
    authed = bool_of_string(response)

    if (authed) then
      lastDj := auth_info.user
      log.debug("Set lastDj to: #{!lastDj} (#{auth_info.user})")
    else
      log.important("Remote DJ authentication failed: #{auth_info.user} authentication returned false")
    end

    authed
  end

  def remote_connected(header) =
    dj = !lastDj
    log.debug("Adding (#{studioName}, #{dj}) pair to active connections")
    ingest.connections := list.add((studioName, dj), !ingest.connections)

    def listToString(str, item) =
      str ^ "#{fst(item)} => #{snd(item)}"
    end
    connectionsDebug = list.fold(listToString, "", !ingest.connections)
    log.debug("Connections After Add: #{connectionsDebug}")

    log.info("#{studioName} connected! DJ: #{dj} - #{header}")

    # Announce source connection
    slack.log(":zap: #{studioName} source connected (*#{ingest.djFor(studioName)}*)")

    # Trigger global connection handler, which will update on-air metadata if
    # this source is top of the precedence stack
    ingest.onDjConnect()
  end

  def remote_disconnected() =
    log.debug("Remote Disconnected")
    dj = ingest.djFor(studioName)

    log("Remote DJ source disconnected! Was: #{dj}")
    slack.log(":end: #{studioName} disconnected (*#{dj}* :micdrop:)")

    ingest.onDjDisconnect()

    # Clear studio DJ variables
    ingest.connections := list.assoc.remove(studioName, !ingest.connections)

    # Reset metadata for other remaining connected streams
    ingest.onDjConnect()
  end

  harbor = audio_to_stereo(input.harbor(mount, port = !ingest.icecastPort, auth = azuracastAuth, icy = true, icy_metadata_charset = "UTF-8", metadata_charset = "UTF-8", on_connect = remote_connected, on_disconnect = remote_disconnected, buffer = 10., max = 15.))
  ignore(output.dummy(harbor, fallible=true))

  # return the source
  if (dropMetadata == true) then
    drop_metadata(harbor)
  else
    harbor
  end
end

# Create an remote DJ source authenticated against Creek's user database
def ingest.makeCreekStreamerSource(studioName, ~mount, ~dropMetadata=false, ~authEndpoint="/api/auth/stream") =
  # Keep track of who the last DJ was so we can monitor when it changes.
  lastDj = ref("")

  def creekAuth(login) =
    auth_info = ingest.parseCredentials(login)

    log.debug("Authenticating Creek DJ: #{auth_info.user}")

    ret = bff.post(authEndpoint, data=[
      ("username", auth_info.user),
      ("password", auth_info.password)
    ])
    log.debug("Creek DJ auth response: #{ret}")

    let json.parse result = ret
    if (result.authenticated == true) then
      djName = result.display_name
      showName = result.show
      endTime = result.end_time

      lastDj := "#{djName}/#{showName} (#{auth_info.user})"
      log.debug("Set lastDj to: #{!lastDj}")

      slack.log(":key: #{studioName} DJ authenticated: *#{djName}*/*#{showName}* (@#{auth_info.user})")
      slack.log("@#{auth_info.user}} :clock10: Remember to disconnected before *#{endTime}* when #{showName} ends!")
    else
      # Auth failed, get reason and push to Slack:
      reason = result.reason
      slack.log(":octagonal_sign: #{studioName} DJ authentication failed: Creek user @#{auth_info.user} not authenticated because: *#{reason}*")
      log.important("Creek DJ #{auth_info.user} authentication failed: #{reason}")
    end

    result.authenticated
  end

  def remote_connected(header) =
    dj = !lastDj
    log.debug("Adding (#{studioName}, #{dj}) pair to active connections")
    ingest.connections := list.add((studioName, dj), !ingest.connections)

    def listToString(str, item) =
      str ^ "#{fst(item)} => #{snd(item)}"
    end
    connectionsDebug = list.fold(listToString, "", !ingest.connections)
    log.debug("Connections After Add: #{connectionsDebug}")

    log.info("#{studioName} connected! DJ: #{dj} - #{header}")

    # Announce source connection
    slack.log(":zap: #{studioName} source connected (*#{ingest.djFor(studioName)}*)")

    # Trigger global connection handler, which will update on-air metadata if
    # this source is top of the precedence stack
    ingest.onDjConnect()
  end

  def remote_disconnected() =
    log.debug("Remote Disconnected")
    dj = ingest.djFor(studioName)

    log("Remote DJ source disconnected! Was: #{dj}")
    slack.log(":end: #{studioName} disconnected (*#{dj}* :micdrop:)")

    ingest.onDjDisconnect()

    # Clear studio DJ variables
    ingest.connections := list.assoc.remove(studioName, !ingest.connections)

    # Reset metadata for other remaining connected streams
    ingest.onDjConnect()
  end

  harbor = audio_to_stereo(input.harbor(mount, port = !ingest.icecastPort, auth = creekAuth, icy = true, icy_metadata_charset = "UTF-8", metadata_charset = "UTF-8", on_connect = remote_connected, on_disconnect = remote_disconnected, buffer = 10., max = 15.))
  ignore(output.dummy(harbor, fallible=true))

  # return the source
  if (dropMetadata == true) then
    drop_metadata(harbor)
  else
    harbor
  end
end

dj_sources = fallback(track_sensitive=false, [
  ingest.makeAzuraCastStreamerSource("Remote DJ", mount="/dj", dropMetadata=true),
  ingest.makeStudioSource("Studio F DJ", mount="/ferry", password=!ingest_studio_a_password, dropMetadata=true),
  ingest.makeStudioSource("Studio A DJ", mount="/studio", password=!ingest_studio_f_password, dropMetadata=true),
  ingest.makeStudioSource("Studio Automation", mount="/automation", password=!ingest_automation_password, dropMetadata=true)
])

# Tracking metadata
#
# Regardless of where our source is connected from, we treat our CMS as the canonical and only source of truth for what
# music is being played. (Hence `dropMetadata=true` on all the Icecast ingestion above.)
#
# Here, we poll the CMS for track changes.

creek_metadata_source = insert_metadata(dj_sources)
dj_sources = creek_metadata_source

# For debugging purposes, we store the last unique track name, and the
# timestamp of when it was registered
last_creek_track = ref(("BFF.fm", timestamp.hms()))

def poll_creek_metadata() =
  last_name = fst(!last_creek_track)
  now = timestamp.hms()

  # Fetch the now playing track from BFF.fm API
  playing = bff.fetch(cacheBust=true, "data/tracks/now.json")
  log.debug("Fetched: #{playing}")

  let json.parse playingData = playing
  artist = playingData.artist
  title = playingData.title
  album = playingData.album
  label = playingData.label

  if (artist != "") then
    playingString = "#{artist} - #{title}"

    # If the currently playing track isn't the same as on last poll:
    if (playingString != last_name) then
      # Update last displayed track title
      last_creek_track := (playingString, now)

      # Chaged metadata so update source metadata as 'new track'
      creek_metadata_source.insert_metadata(new_track=true, [("title", playingString)])

        # Scrobble new tracks to Last.FM
      lastfm.scrobble(artist=artist, album=album, track=title)

      # Log Now Playing to TuneIn AIR API
      tunein.nowPlaying(artist=artist, track=title, album=album)

      # Log to Slack
      slack.log(channel="now_playing", ":notes: #{artist} - #{title} (#{album}) [#{label}]")
    end
  else
    # No track: Display the current show/host/station
    show = bff.fetch(cacheBust=true, "data/shows/now.text")

    # Generally, BFF.fm should always have a show in the schedule (even placeholders), but
    # just in case there's a gap, or a data error, fall back to
    show = if (show == "") then
      "BFF.fm"
    else
      show
    end

    if (show != last_name) then
      # Update last displayed track title
      last_creek_track := (show, now)

      # Update source metadata, but not as a 'track'
      creek_metadata_source.insert_metadata(new_track=false, [("title", show)])

      # Log to Slack
      slack.log(channel="now_playing", ":radio: #{show}")

      # Log Now Playing 'commerical'/non-music to TuneIn
      # Split Artist - Name format and send to AIR
      # TODO: Might be cleaner with a JSON response from Creek
      parts = list.map(string.trim, string.split(separator="-", show))
      if (list.length(parts) == 2) then
        attribution = list.hd(default="", parts)
        name = list.nth(default="", parts, 1)
        tunein.nonMusic(attribution=attribution, name=name)
      end
    end
  end

  # Return the timeout for the next poll
  (10.)
end

add_timeout(fast=false, 10., poll_creek_metadata)

emergency_broadcast = ingest.makeStudioSource("Emergency Broadcast", mount="/emergency", username="ebs", password=!ingest_emergency_password)

# Add the no-ice metadata stream to the stack before the global metadata listener
radio = fallback(track_sensitive=false, [emergency_broadcast, dj_sources, radio])

### END: BFF.fm Ingest Harbors ###

# Local Broadcasts
output.icecast(%mp3(samplerate=44100, stereo=true, bitrate=128, id3v2=true), id="local_1", host = "127.0.0.1", port = 8000, password = "(PASSWORD)", mount = "/radio.mp3", name = "BFF.fm Azupgrade Station", description = "Testing the Azuracast Upgrade", genre = "Unclassifiable", url = "https://bff.fm", public = false, encoding = "UTF-8", radio)

# Remote Relays
